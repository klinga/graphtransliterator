{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marshmallow # requires 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marshmallow import Schema, fields, pprint, validates_schema, ValidationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marshmallow.Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "RULE_RE = re.compile(\n",
    "    r\"(?:\\(((?:\\s?<.+?>\\s+)+)?(.+?)\\s?\\) |((?:\\s?<.+?>\\s+)+)?)?\"\n",
    "    r\"((?:\\n|\\r|.)+?)\"\n",
    "    r\"(?:\"\n",
    "    r\"\\s+(?:\\((.+?)((?:\\s+<.+?>?)?)\\)$)\"\n",
    "    r\"|\"\n",
    "    r\"((?:\\s+<.+?>)+)\"\n",
    "    r\"|\"\n",
    "    r\"$)\"\n",
    ")\n",
    "\n",
    "ONMATCH_RE = re.compile(\n",
    "    r\"^(\" r\"(?:<[^+< \\s]+>\\s*)+\" r\")\" r\"\\+\" r\"(\" r\"(?:\\s*<[^+<]+>)+)\\s*$\"\n",
    ")\n",
    "\n",
    "ONMATCH_CLASS_RE = re.compile(r\"(?<=<)[^+< \\s]+(?=>)\")\n",
    "\n",
    "\n",
    "from graphtransliterator import WhitespaceRules\n",
    "\n",
    "from marshmallow import Schema, fields, pprint, post_load, validate\n",
    "\n",
    "class WhitespaceSettingsSchema(Schema):\n",
    "    default = fields.Str(required=True)\n",
    "    token_class = fields.Str(required=True)\n",
    "    consolidate = fields.Boolean(required=True)\n",
    "\n",
    "\n",
    "#class EasyReadingRuleSchema(Schema):\n",
    "    \n",
    "class EasyReadingSettingsSchema(Schema):\n",
    "    tokens = fields.Dict(\n",
    "        keys=fields.Str(),\n",
    "        values=fields.List(fields.Str()),\n",
    "        required=True,\n",
    "    )\n",
    "    rules = fields.Dict(\n",
    "        keys=fields.Str(validate=validate.Regexp(RULE_RE)),\n",
    "        values=fields.Str(),\n",
    "        required=True\n",
    "    )\n",
    "    onmatch_rules = fields.Dict(\n",
    "        keys=fields.Str(validate=validate.Regexp(ONMATCH_RE)),\n",
    "        values=fields.Str(),\n",
    "        required=False\n",
    "    )\n",
    "    metadata = fields.Dict(\n",
    "        keys=fields.Str(),\n",
    "        # no restriction on values\n",
    "        required=False\n",
    "    )\n",
    "    whitespace = fields.Nested(WhitespaceSettingsSchema)\n",
    "    \n",
    "class UserSchema(Schema):\n",
    "    name = fields.Str()\n",
    "    email = fields.Email()\n",
    "    created_at = fields.DateTime()\n",
    "    \n",
    "EASYREADING_SETTINGS_SCHEMA = {\n",
    "    \"rules\": {\n",
    "        \"type\": \"dict\",\n",
    "        \"required\": True,\n",
    "        \"keysrules\": {\"type\": \"string\", \"regex\": RULE_RE.pattern},\n",
    "        \"valuesrules\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"onmatch_rules\": {\n",
    "        \"type\": \"list\",\n",
    "        \"required\": False,\n",
    "        \"schema\": {\n",
    "            \"type\": \"dict\",\n",
    "            \"minlength\": 1,\n",
    "            \"maxlength\": 1,\n",
    "            \"keysrules\": {\"type\": \"string\", \"regex\": ONMATCH_RE.pattern},\n",
    "            \"valuesrules\": {\"type\": \"string\"},\n",
    "        },\n",
    "    },\n",
    "    \"tokens\": {\n",
    "        \"type\": \"dict\",\n",
    "        \"required\": True,\n",
    "        \"keysrules\": {\"type\": \"string\"},\n",
    "        \"valuesrules\": {\"type\": \"list\", \"schema\": {\"type\": \"string\"}},\n",
    "    },\n",
    "    \"whitespace\": {\n",
    "        \"type\": \"dict\",\n",
    "        \"required\": True,\n",
    "        \"schema\": {\n",
    "            \"default\": {\"required\": True, \"type\": \"string\"},\n",
    "            \"token_class\": {\"required\": True, \"type\": \"string\"},\n",
    "            \"consolidate\": {\"required\": True, \"type\": \"boolean\"},\n",
    "        },\n",
    "    },\n",
    "    \"metadata\": {\"type\": \"dict\", \"required\": False},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphtransliterator\n",
    "import yaml\n",
    "yaml_ = \"\"\"\n",
    "   tokens:\n",
    "     a: [vowel]               # type of token (\"a\") and its class (vowel)\n",
    "     bb: [consonant, b_class] # type of token (\"bb\") and its classes (consonant, b_class)\n",
    "     ' ': [wb]                # type of token (\" \") and its class (\"wb\", for wordbreak)\n",
    "   rules:\n",
    "     a: A       # transliterate \"a\" to \"A\"\n",
    "     bb: B      # transliterate \"bb\" to \"B\"\n",
    "     a a: <2AS> # transliterate (\"a\", \"a\") to \"<2AS>\"\n",
    "     ' ': ' '   # transliterate ' ' to ' '\n",
    "   whitespace:\n",
    "     default: \" \"        # default whitespace token\n",
    "     consolidate: false  # whitespace should not be consolidated\n",
    "     token_class: wb     # whitespace token class\n",
    " \"\"\"\n",
    "data = yaml.safe_load(yaml_)\n",
    "EasyReadingSettingsSchema().load(data)#['whitespace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    yaml_str = r\"\"\"\n",
    "    tokens:\n",
    "      a: [token, class1]\n",
    "      b: [token, class2]\n",
    "      u: [token]\n",
    "      ' ': [wb]\n",
    "    rules:\n",
    "      a: A\n",
    "      b: B\n",
    "      <wb> u: \\N{DEVANAGARI LETTER U}\n",
    "    onmatch_rules:\n",
    "      -\n",
    "        <class1> + <class2>: \",\"\n",
    "      -\n",
    "        <class1> + <token>: \\N{DEVANAGARI SIGN VIRAMA}\n",
    "    whitespace:\n",
    "      default: ' '\n",
    "      token_class: 'wb'\n",
    "      consolidate: true\n",
    "    metadata:\n",
    "      author: Author\n",
    "    \"\"\"\n",
    "\n",
    "    input_dict = yaml.safe_load(yaml_str)\n",
    "    assert \"a\" in GraphTransliterator.from_dict(input_dict).tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EASYREADING_SETTINGS_SCHEMA = {\n",
    "    \"rules\": {\n",
    "        \"type\": \"dict\",\n",
    "        \"required\": True,\n",
    "        \"keysrules\": {\"type\": \"string\", \"regex\": RULE_RE.pattern},\n",
    "        \"valuesrules\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"onmatch_rules\": {\n",
    "        \"type\": \"list\",\n",
    "        \"required\": False,\n",
    "        \"schema\": {\n",
    "            \"type\": \"dict\",\n",
    "            \"minlength\": 1,\n",
    "            \"maxlength\": 1,\n",
    "            \"keysrules\": {\"type\": \"string\", \"regex\": ONMATCH_RE.pattern},\n",
    "            \"valuesrules\": {\"type\": \"string\"},\n",
    "        },\n",
    "    },\n",
    "    \"tokens\": {\n",
    "        \"type\": \"dict\",\n",
    "        \"required\": True,\n",
    "        \"keysrules\": {\"type\": \"string\"},\n",
    "        \"valuesrules\": {\"type\": \"list\", \"schema\": {\"type\": \"string\"}},\n",
    "    },\n",
    "    \"whitespace\": {\n",
    "        \"type\": \"dict\",\n",
    "        \"required\": True,\n",
    "        \"schema\": {\n",
    "            \"default\": {\"required\": True, \"type\": \"string\"},\n",
    "            \"token_class\": {\"required\": True, \"type\": \"string\"},\n",
    "            \"consolidate\": {\"required\": True, \"type\": \"boolean\"},\n",
    "        },\n",
    "    },\n",
    "    \"metadata\": {\"type\": \"dict\", \"required\": False},\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    validator = Validator()\n",
    "\n",
    "    tokens_schema = {\n",
    "        \"tokens\": {\n",
    "            \"keysrules\": {\"type\": \"string\"},\n",
    "            \"type\": \"dict\",\n",
    "            \"valuesrules\": {\"schema\": {\"type\": \"string\"}, \"type\": \"list\"},\n",
    "        }\n",
    "    }\n",
    "\n",
    "    validator.validate({\"tokens\": tokens}, tokens_schema)\n",
    "\n",
    "    if validator.errors:\n",
    "        raise ValueError(\n",
    "            \"GraphTransliterator `tokens` contains invalid entries:\\n %s\"\n",
    "            % validator.errors\n",
    "        )\n",
    "\n",
    "    token_keys = list(tokens.keys())\n",
    "    token_classes = list(set().union(*tokens.values()))\n",
    "\n",
    "    rules_schema = {\n",
    "        \"type\": \"list\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"dict\",\n",
    "            \"schema\": {\n",
    "                \"tokens\": {\"required\": True, \"type\": \"list\", \"allowed\": token_keys},\n",
    "                \"prev_classes\": {\n",
    "                    \"required\": False,\n",
    "                    \"type\": \"list\",\n",
    "                    \"allowed\": token_classes,\n",
    "                },\n",
    "                \"prev_tokens\": {\n",
    "                    \"required\": False,\n",
    "                    \"type\": \"list\",\n",
    "                    \"allowed\": token_keys,\n",
    "                },\n",
    "                \"next_tokens\": {\n",
    "                    \"required\": False,\n",
    "                    \"type\": \"list\",\n",
    "                    \"allowed\": token_keys,\n",
    "                },\n",
    "                \"next_classes\": {\n",
    "                    \"required\": False,\n",
    "                    \"type\": \"list\",\n",
    "                    \"allowed\": token_classes,\n",
    "                },\n",
    "                \"production\": {\"required\": True, \"type\": \"string\"},\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    onmatch_rules_schema = {\n",
    "        \"type\": \"list\",\n",
    "        \"required\": False,\n",
    "        \"schema\": {\n",
    "            \"type\": \"dict\",\n",
    "            \"schema\": {\n",
    "                \"prev_classes\": {\"type\": \"list\", \"schema\": {\"allowed\": token_classes}},\n",
    "                \"production\": {\"type\": \"string\"},\n",
    "                \"next_classes\": {\"type\": \"list\", \"schema\": {\"allowed\": token_classes}},\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    whitespace_schema = {\n",
    "        \"type\": \"dict\",\n",
    "        \"required\": True,\n",
    "        \"schema\": {\n",
    "            \"default\": {\"type\": \"string\", \"allowed\": token_keys},\n",
    "            \"token_class\": {\"type\": \"string\", \"allowed\": token_classes},\n",
    "            \"consolidate\": {\"type\": \"boolean\"},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    metadata_schema = {\"type\": \"dict\", \"required\": False}\n",
    "\n",
    "    schemas = {\n",
    "        \"whitespace\": whitespace_schema,\n",
    "        \"onmatch_rules\": onmatch_rules_schema,\n",
    "        \"rules\": rules_schema,\n",
    "        \"metadata\": metadata_schema,\n",
    "    }\n",
    "\n",
    "    document = {\n",
    "        \"whitespace\": whitespace,\n",
    "        \"rules\": rules,\n",
    "        \"onmatch_rules\": onmatch_rules,\n",
    "        \"metadata\": metadata,\n",
    "    }  # Cerberus needs a dict\n",
    "\n",
    "    validator.validate(document, schemas)\n",
    "\n",
    "    if validator.errors:\n",
    "        raise ValueError(\n",
    "            \"GraphTransliterator settings contain invalid entries:\\n%s\"\n",
    "            % validator.errors\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ScannerError",
     "evalue": "mapping values are not allowed here\n  in \"<unicode string>\", line 4, column 27:\n            ' ': wb      rules:\n                              ^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScannerError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-896924ca5dc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \"\"\"\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraphtransliterator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphTransliterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mGraphTransliterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_yaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gits/graphtransliterator/graphtransliterator/core.py\u001b[0m in \u001b[0;36mfrom_yaml\u001b[0;34m(cls, yaml_str, charnames_escaped, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m             \u001b[0myaml_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unescape_charnames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myaml_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m         \u001b[0msettings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myaml_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/__init__.py\u001b[0m in \u001b[0;36msafe_load\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msafe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muntrusted\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \"\"\"\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSafeLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msafe_load_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(stream, Loader)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_single_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/constructor.py\u001b[0m in \u001b[0;36mget_single_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_single_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Ensure that the stream contains a single document and construct it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_single_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/composer.py\u001b[0m in \u001b[0;36mget_single_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStreamEndEvent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Ensure that the stream contains no more documents.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/composer.py\u001b[0m in \u001b[0;36mcompose_document\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Compose the root node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Drop the DOCUMENT-END event.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/composer.py\u001b[0m in \u001b[0;36mcompose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_sequence_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMappingStartEvent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_mapping_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascend_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/composer.py\u001b[0m in \u001b[0;36mcompose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m#            \"found duplicate key\", key_event.start_mark)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mitem_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;31m#node.value[item_key] = item_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/composer.py\u001b[0m in \u001b[0;36mcompose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_sequence_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMappingStartEvent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_mapping_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascend_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/composer.py\u001b[0m in \u001b[0;36mcompose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0manchor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMappingEndEvent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;31m#key_event = self.peek_event()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mitem_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/parser.py\u001b[0m in \u001b[0;36mcheck_event\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_event\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_event\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_event\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/parser.py\u001b[0m in \u001b[0;36mparse_block_mapping_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_block_mapping_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyToken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyToken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueToken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlockEndToken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/scanner.py\u001b[0m in \u001b[0;36mcheck_token\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Check if the next token is one of the given types.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_more_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_more_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/scanner.py\u001b[0m in \u001b[0;36mfetch_more_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;31m# Is it the value indicator?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m':'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Is it an alias?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/yaml/scanner.py\u001b[0m in \u001b[0;36mfetch_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m                     raise ScannerError(None, None,\n\u001b[1;32m    578\u001b[0m                             \u001b[0;34m\"mapping values are not allowed here\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                             self.get_mark())\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# If this value starts a new block mapping, we need to add\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mScannerError\u001b[0m: mapping values are not allowed here\n  in \"<unicode string>\", line 4, column 27:\n            ' ': wb      rules:\n                              ^"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import graphtransliterator\n",
    "importlib.reload(graphtransliterator)\n",
    "bad_yaml = \"\"\"\n",
    "      tokens:\n",
    "        a: class1\n",
    "        ' ': wb\\\n",
    "      rules:\n",
    "        a: A\n",
    "      whitespace:\n",
    "        default: BAD_TOKEN\n",
    "        consolidate: true\n",
    "        token_class: BAD_CLASS\n",
    "    \"\"\"\n",
    "from graphtransliterator import GraphTransliterator\n",
    "GraphTransliterator.from_yaml(bad_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_yaml = \"\"\"\n",
    "          tokens:\n",
    "            a: [class1]\n",
    "            ' ': [wb]\n",
    "          rules:\n",
    "            a <class_nonexisting>: A\n",
    "          whitespace:\n",
    "            default: ' '\n",
    "            consolidate: true\n",
    "            token_class: wb\n",
    "    \"\"\"\n",
    "import importlib\n",
    "import graphtransliterator\n",
    "importlib.reload(graphtransliterator)\n",
    "graphtransliterator.GraphTransliterator.from_yaml(bad_yaml)\n",
    "import yaml\n",
    "x = graphtransliterator.process._process_easyreading_settings(graphtransliterator.validate.EasyReadingSettingsSchema().load(yaml.safe_load(bad_yaml)))\n",
    "graphtransliterator.validate.SettingsSchema().load(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import graphtransliterator\n",
    "importlib.reload(graphtransliterator)\n",
    "#from graphtransliterator import GraphTransliterator\n",
    "YAML = r\"\"\"\n",
    "tokens:\n",
    "    a: [class_a]\n",
    "    b: [class_b]\n",
    "    c: [class_c]\n",
    "    \" \": [wb]\n",
    "    d: []\n",
    "    Aa: [contrained_rule]\n",
    "rules:\n",
    "    a: A\n",
    "    b: B\n",
    "    <class_c> <class_c> a: A(AFTER_CLASS_C_AND_CLASS_C)\n",
    "    (<class_c> b) a: A(AFTER_B_AND_CLASS_C)\n",
    "    (<class_c> b b) a a: AA(AFTER_BB_AND_CLASS_C)\n",
    "    a <class_c>: A(BEFORE_CLASS_C)\n",
    "    a b (c <class_b>): AB(BEFORE_C_AND_CLASS_B)\n",
    "    c: C\n",
    "    c c: C*2\n",
    "    a (b b b): A(BEFORE_B_B_B)\n",
    "    d (c <class_a>): D(BEFORE_C_AND_CLASS_A)\n",
    "    (b b) a: A(AFTER_B_B)\n",
    "    <wb> Aa: A(ONLY_A_CONSTRAINED_RULE)\n",
    "onmatch_rules:\n",
    "    -\n",
    "        <class_a> <class_b> + <class_a> <class_b>: \"!\"\n",
    "    -\n",
    "        <class_a> + <class_b>: \",\"\n",
    "whitespace:\n",
    "    default: ' '\n",
    "    consolidate: True\n",
    "    token_class: wb\n",
    "\"\"\"\n",
    "gt = graphtransliterator.GraphTransliterator.from_yaml(YAML)\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleSchema(Schema):\n",
    "    production = fields.Str()\n",
    "    tokens = fields.List(fields.Str())\n",
    "\n",
    "class OnMatchRuleSchema(Schema):\n",
    "    prev_classes = fields.List(fields.Str())\n",
    "    next_classes = fields.List(fields.Str())\n",
    "    production = fields.Str()\n",
    "    \n",
    "class SettingsSchema(Schema):\n",
    "    tokens = fields.Dict(\n",
    "        keys=fields.Str(),\n",
    "        values=fields.List(fields.Str()),\n",
    "        required=True,\n",
    "    )\n",
    "    rules = fields.Nested(RuleSchema, many=True, required=True)\n",
    "    whitespace = fields.Nested(WhitespaceSettingsSchema, many=False, required=True)\n",
    "    metadata = fields.Dict(\n",
    "        keys=fields.Str(), # no restriction on values\n",
    "        required=False\n",
    "    )\n",
    "    onmatch_rules = fields.Nested(OnMatchRuleSchema, many=True, required=False)\n",
    "    whitespace = fields.Nested(WhitespaceSettingsSchema, required=True)\n",
    "\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    @validates_schema\n",
    "    def validate_token_classes(self, data, **kwargs):\n",
    "        errors = defaultdict(list)\n",
    "        token_classes = list(set().union(*data['tokens'].values()))\n",
    "\n",
    "        # validate onmatch_rules\n",
    "        for onmatch_rule in data['onmatch_rules']:\n",
    "            for _ in onmatch_rule['prev_classes']:\n",
    "                if not _ in token_classes:\n",
    "                    errors['onmatch_rules'].append('Invalid token class \"{}\" in prev_classes of OnMatchRule {}'.format(_, onmatch_rule))\n",
    "            for _ in onmatch_rule['next_classes']:\n",
    "                if not _ in token_classes:\n",
    "                    errors['onmatch_rules'].append('Invalid token class \"{}\" in next_classes of OnMatchRule {}'.format(_, onmatch_rule))\n",
    "        # validate whitespace token_class\n",
    "        \n",
    "        whitespace = data['whitespace']\n",
    "        whitespace_token_class = whitespace['token_class']\n",
    "        if not whitespace_token_class in token_classes:\n",
    "            errors['whitespace'].append('Invalid token class \"{}\" in whitespace.'.format(whitespace_token_class, whitespace))\n",
    "        if errors:\n",
    "            raise ValidationError(dict(errors))\n",
    "\n",
    "\n",
    "    @validates_schema\n",
    "    def validate_tokens(self, data, **kwargs):\n",
    "        errors = defaultdict(list)\n",
    "        token_types = data['tokens'].keys()\n",
    "        \n",
    "        # validate whitespace\n",
    "        whitespace = data['whitespace']\n",
    "        default_whitespace = whitespace['default']\n",
    "        if default_whitespace not in token_types:\n",
    "            errors['whitespace'].append('Invalid default token \"{}\" in whitespace.'.format(default_whitespace))\n",
    "\n",
    "        # validate rules\n",
    "        rules = data['rules']\n",
    "        for rule in rules:\n",
    "            for _ in rule['tokens']:\n",
    "                if not _ in token_types:\n",
    "                    errors['rules'].append('Invalid token \"{}\" in rule {}'.format(_, rule))\n",
    "        if errors:\n",
    "            raise ValidationError(dict(errors))\n",
    "\n",
    "settings = {\n",
    "'tokens': {'a': ['vowel'],\n",
    "           ' ': ['wb']},\n",
    "'rules': [\n",
    "{'production': 'A', 'tokens': ['a']},\n",
    " {'production': ' ', 'tokens': [' ']}],\n",
    "  'onmatch_rules': [\n",
    "       {'prev_classes': ['vozwel'],\n",
    "        'next_classes': ['vowel'],\n",
    "        'production': ','}],\n",
    "   'whitespace': {\n",
    "       'default': ' x',\n",
    "       'consolidate': False,\n",
    "       'token_class': 'wb'},\n",
    "   'metadata': {\n",
    "       'author': 'Author McAuthorson'}\n",
    " }\n",
    "\n",
    "x=SettingsSchema().load(settings)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SettingsSchema.validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classes = list(set().union(*data['tokens'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
